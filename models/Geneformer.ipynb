{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234afff3",
   "metadata": {},
   "source": [
    "# Geneformer\n"
    "This is a modified version of the code provided by the Geneformer authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c0291",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe6178-ea4d-478a-80a8-65ffaa4c1820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "GPU_NUMBER = [0]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(s) for s in GPU_NUMBER])\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9885d9f-00ac-4c84-b6a3-b7b648a90f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import datetime\n",
    "import pickle\n",
    "import subprocess\n",
    "import seaborn as sns; sns.set()\n",
    "from datasets import load_from_disk, load_dataset, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer\n",
    "from transformers.training_args import TrainingArguments\n",
    "import anndata\n",
    "from anndata import AnnData\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import scanpy as sp\n",
    "from geneformer import DataCollatorForCellClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ec07e6",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a761be-be9e-46bf-b053-562be15a6687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_csv_dataset(path):\n",
    "    def convert_list_values_to_int(x):\n",
    "        lst = [int(i) for i in x]\n",
    "        return lst\n",
    "    \n",
    "    dataset = pd.read_csv(path)\n",
    "    \n",
    "    dataset.drop(labels='Unnamed: 0', axis=1, inplace=True)\n",
    "    dataset['label'] = dataset['label'].astype(int)\n",
    "    dataset['input_ids'] = dataset['input_ids'].str.strip('[]').str.split(', ')\n",
    "    dataset['input_ids'] = dataset['input_ids'].apply(convert_list_values_to_int)\n",
    "    dataset['length'] = dataset['length'].astype(int)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288bd7c-fb3c-4242-a3d9-4f94904df8eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = load_csv_dataset('ms_train.csv')\n",
    "test_dataset = load_csv_dataset('ms_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b56c1-06d5-4d5e-a411-cd0b2c3748d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_to_type = pd.read_pickle('dictionaries/ms_train.pkl')\n",
    "type_to_index = pd.read_pickle('dictionaries/ms_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7dbac8",
   "metadata": {},
   "source": [
    "## Hyperparameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b1cfb-f5cb-460e-ae77-769522ece054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # calculate accuracy and macro f1 using sklearn's function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prc = precision_score(labels, preds, average='macro')\n",
    "    rcl = recall_score(labels, preds, average='macro')\n",
    "    macro_f1 = f1_score(labels, preds, average='macro')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': prc,\n",
    "        'recall': rcl,\n",
    "        'macro_f1': macro_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24e1ab7-0131-44bd-b458-1ce5ba31853e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set model parameters\n",
    "# max input size\n",
    "max_input_size = 2 ** 11 # 2048\n",
    "\n",
    "# set training hyperparameters\n",
    "# max learning rate\n",
    "max_lr = 5e-6\n",
    "# how many pretrained layers to freeze\n",
    "freeze_layers = 0\n",
    "# number gpus\n",
    "num_gpus = 1\n",
    "# number cpu cores\n",
    "num_proc = 16\n",
    "# batch size for training and eval\n",
    "geneformer_batch_size = 1\n",
    "# learning schedule\n",
    "lr_schedule_fn = \"linear\"\n",
    "# warmup steps\n",
    "warmup_steps = 500\n",
    "# number of epochs\n",
    "epochs = 1\n",
    "# optimizer\n",
    "optimizer = \"adamw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e33b15-d126-44ef-8ba1-18610f24cecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'ms_default'\n",
    "split = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da877e2",
   "metadata": {},
   "source": [
    "## Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05164c24-5fbf-4372-b26c-a43f3777a88d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "organ_trainset = train_dataset\n",
    "organ_evalset = test_dataset\n",
    "organ_label_dict = type_to_index\n",
    "\n",
    "# set logging steps\n",
    "logging_steps = round(len(organ_trainset)/geneformer_batch_size/10)\n",
    "\n",
    "# reload pretrained model\n",
    "model = BertForSequenceClassification.from_pretrained(\"geneformer-12L-30M\", \n",
    "                                                  num_labels=len(organ_label_dict.keys()),\n",
    "                                                  output_attentions = False,\n",
    "                                                  output_hidden_states = False).to(\"cuda\")\n",
    "\n",
    "# define output directory path\n",
    "current_date = datetime.datetime.now()\n",
    "datestamp = f\"{str(current_date.year)[-2:]}{current_date.month:02d}{current_date.day:02d}\"\n",
    "output_dir = f\"./results/{model_name}/split_{split}/\"\n",
    "\n",
    "# ensure not overwriting previously saved model\n",
    "saved_model_test = os.path.join(output_dir, f\"pytorch_model.bin\")\n",
    "if os.path.isfile(saved_model_test) == True:\n",
    "    raise Exception(\"Model already saved to this directory.\")\n",
    "\n",
    "# make output directory\n",
    "subprocess.call(f'mkdir {output_dir}', shell=True)\n",
    "\n",
    "# set training arguments\n",
    "training_args = {\n",
    "    \"learning_rate\": max_lr,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"logging_steps\": logging_steps,\n",
    "    \"group_by_length\": True,\n",
    "    \"length_column_name\": \"length\",\n",
    "    \"disable_tqdm\": False,\n",
    "    \"lr_scheduler_type\": lr_schedule_fn,\n",
    "    \"warmup_steps\": warmup_steps,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"per_device_train_batch_size\": geneformer_batch_size,\n",
    "    \"per_device_eval_batch_size\": geneformer_batch_size,\n",
    "    \"num_train_epochs\": epochs,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"output_dir\": output_dir,\n",
    "}\n",
    "\n",
    "training_args_init = TrainingArguments(**training_args)\n",
    "\n",
    "# create the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_init,\n",
    "    data_collator=DataCollatorForCellClassification(),\n",
    "    train_dataset=organ_trainset,\n",
    "    eval_dataset=organ_evalset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "# train the cell type classifier\n",
    "trainer.train()\n",
    "max_memory_reserved = torch.cuda.max_memory_reserved() / 1e9\n",
    "print(f'Memory usage: {max_memory_reserved}')\n",
    "predictions = trainer.predict(organ_evalset)\n",
    "with open(f\"{output_dir}predictions.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(predictions, fp)\n",
    "trainer.save_metrics(\"eval\", predictions.metrics)\n",
    "trainer.save_model(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "eba1599a1f7e611c14c87ccff6793920aa63510b01fc0e229d6dd014149b8829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
