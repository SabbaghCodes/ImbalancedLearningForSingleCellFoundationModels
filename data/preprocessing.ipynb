{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234afff3",
   "metadata": {},
   "source": [
    "# Preprocessing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08f639-cbee-4079-a345-087d226f1a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "import scvi\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef12d23-04b3-4b8a-a0d8-426119cc1fc9",
   "metadata": {},
   "source": [
    "## Oversampling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec32bc40-a73c-4bcc-aff2-eda1c8915186",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\"data/ms_train.h5ad\")\n",
    "type_to_index = dict(zip(adata.obs['celltype'].unique(), range(len(adata.obs['celltype'].unique()))))\n",
    "index_to_type = dict(zip(range(len(adata.obs['celltype'].unique())), adata.obs['celltype'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69225ca6-f582-42c0-bb4b-b5d0a04dc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adata.X\n",
    "vr = adata.var\n",
    "y = [type_to_index[i] for i in list(adata.obs['celltype'])]\n",
    "\n",
    "sampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "\n",
    "adata_resampled = AnnData(X_resampled, obs={'celltype': y_resampled}, var=vr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783cf92c-9817-4568-bca2-6462d39cf557",
   "metadata": {},
   "source": [
    "## Undersampling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ead48-33c4-4c99-95d3-6d89395fe2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\"data/ms_train.h5ad\")\n",
    "type_to_index = dict(zip(adata.obs['celltype'].unique(), range(len(adata.obs['celltype'].unique()))))\n",
    "index_to_type = dict(zip(range(len(adata.obs['celltype'].unique())), adata.obs['celltype'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c72b0d-abf0-4d1c-86b9-74a60a368fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_with_threshold(adata, threshold):\n",
    "    celltypes_dict = dict(adata.obs['celltype'].value_counts())\n",
    "    to_undersample_dict = {}\n",
    "    to_keep_dict = {}\n",
    "\n",
    "    for celltype, samples in celltypes_dict.items():\n",
    "        if samples >= threshold:\n",
    "            to_undersample_dict[celltype] = samples\n",
    "        else:\n",
    "            to_keep_dict[celltype] = samples\n",
    "            \n",
    "    min_class = min(to_undersample_dict, key=celltypes_dict.get)\n",
    "    threshold_class = adata[adata[adata.obs['celltype'] == min_class].obs.sample(threshold).index]\n",
    "    undersample_adata = adata[adata.obs['celltype'] != min_class]\n",
    "    undersample_adata = undersample_adata.concatenate(threshold_class)\n",
    "    \n",
    "    keep_data = adata[adata.obs['celltype'].isin(to_keep_dict.keys())]\n",
    "    undersample_data = undersample_adata[undersample_adata.obs['celltype'].isin(to_undersample_dict.keys())]\n",
    "    \n",
    "    X = undersample_data.X\n",
    "    vr = undersample_data.var\n",
    "    # Assuming `adata` contains `.obs` attribute with cell labels\n",
    "    y = [type_to_index[i] for i in list(undersample_data.obs['celltype'])]\n",
    "\n",
    "    # Create a SMOTE object\n",
    "    under_sampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "    # Resample the data\n",
    "    X_resampled, y_resampled = under_sampler.fit_resample(X, y)\n",
    "\n",
    "    # Create a new AnnData object with the resampled data\n",
    "    adata_resampled = AnnData(X_resampled, obs={'celltype': y_resampled, 'str_batch': 0}, var=vr)\n",
    "    keep_data.obs['celltype'] = keep_data.obs['celltype'].apply(lambda x: type_to_index[x])\n",
    "    adata_resampled = adata_resampled.concatenate(keep_data)\n",
    "    adata_resampled.obs['str_batch'] = 0\n",
    "\n",
    "    return adata_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c03ccd-44b8-4b34-877a-896ff916cf88",
   "metadata": {},
   "source": [
    "## Imputation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff7392-6892-448c-9d2a-ce034aaaa368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_adata = scvi.data.read_h5ad('data/ms_train.h5ad') \n",
    "counts_dict = dict(adata.obs['celltype'].value_counts())\n",
    "threshold = # pick a threshold\n",
    "adata = adata[adata.obs['celltype'].map(counts_dict).astype(int) <= threshold]\n",
    "adata = adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b673f8-fc28-4211-b49a-46bfdaf00ad0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_continue = True\n",
    "\n",
    "while is_continue:\n",
    "    # filtering class that have counts under the specified threshold (to oversample)\n",
    "    counts_dict = dict(new_adata.obs['celltype'].value_counts())\n",
    "    print(counts_dict)\n",
    "    adata = adata[adata.obs['celltype'].map(counts_dict).astype(int) <= threshold]\n",
    "    adata = adata.copy()\n",
    "    scvi.model.SCVI.setup_anndata(adata)\n",
    "    model = scvi.model.SCVI(adata)\n",
    "    model.train()\n",
    "    imputed_adata = model.get_normalized_expression()\n",
    "    imputed_adata = AnnData(imputed_adata, obs=adata.obs, var=adata.var, uns=adata.uns, obsm=adata.obsm, varm=adata.varm)\n",
    "    \n",
    "    add_adata = imputed_adata[imputed_adata.obs['celltype'].map(counts_dict).astype(int) <= threshold]\n",
    "    add_dict = {key: value for key, value in counts_dict.items() if value < threshold}\n",
    "    \n",
    "    if add_dict == {}:\n",
    "        is_continue = False\n",
    "    \n",
    "    for celltype, count in add_dict.items():\n",
    "        concat_adata = imputed_adata[imputed_adata.obs['celltype'] == celltype]\n",
    "        \n",
    "        concat_adata_size = concat_adata.shape[0]\n",
    "        new_adata_size = counts_dict[celltype]\n",
    "        \n",
    "        if new_adata_size + concat_adata_size > threshold:\n",
    "            n_obs = threshold - new_adata_size\n",
    "            sp.pp.subsample(concat_adata, n_obs=n_obs)\n",
    "        new_adata = new_adata.concatenate(concat_adata)\n",
    "    try:\n",
    "        new_adata.write_h5ad('ms_train.h5ad')\n",
    "    except:\n",
    "        new_adata.write('ms_train.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd3b98-5409-4105-b7af-f1ff64ea6a72",
   "metadata": {},
   "source": [
    "## Geneformer's converting the gene expression matrix into ordinal gene tokens function (oversampling and undersampling embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3767f-08d7-48f3-beb4-710f18736052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_h5ad_dataset(path, saving_name='data', is_save=False, is_oversample=False, is_undersample=False):\n",
    "    inp_list = []\n",
    "    len_list = []\n",
    "    \n",
    "    def add_input_ids(row):\n",
    "        inp_list.append(row.sort_values(ascending=False).index.tolist()[:sum(row.gt(0))])\n",
    "    \n",
    "    def add_len(row):\n",
    "        len_list.append(len(row['input_ids']))\n",
    "        \n",
    "    def convert_naming(name, name_dict):\n",
    "        return name_dict[name]\n",
    "        \n",
    "    dataset_base = anndata.read_h5ad(path)\n",
    "    unique_nums = len(dataset_base.obs['celltype'].unique())\n",
    "\n",
    "    index_to_type = dict(zip(range(unique_nums), list(dataset_base.obs['celltype'].unique())))\n",
    "    type_to_index = dict(zip(list(dataset_base.obs['celltype'].unique()), range(unique_nums)))\n",
    "    \n",
    "    # dataset_base.obs['celltype'] =  dataset_base.obs['celltype'].apply(lambda x: convert_naming(x, type_to_index))\n",
    "    \n",
    "    if is_oversample:\n",
    "        sampler = RandomOverSampler(random_state=42)\n",
    "        X_resampled, y_resampled = sampler.fit_resample(dataset_base.X, dataset_base.obs['celltype'])\n",
    "        dataset_base = AnnData(X_resampled, obs={'celltype': y_resampled.values})\n",
    "        \n",
    "    if is_undersample:\n",
    "        sampler = RandomUnderSampler(random_state=42)\n",
    "        X_resampled, y_resampled = sampler.fit_resample(dataset_base.X, dataset_base.obs['celltype'])\n",
    "        dataset_base = AnnData(X_resampled, obs={'celltype': y_resampled.values})\n",
    "        \n",
    "    dataset = dataset_base.to_df()\n",
    "    dataset.rename(columns={x:y for x,y in zip(dataset.columns,range(0,len(dataset.columns)))}, inplace=True)\n",
    "    \n",
    "    for row in range(len(dataset)):\n",
    "        add_input_ids(dataset.iloc[row])\n",
    "    dataset['input_ids'] = inp_list\n",
    "    \n",
    "    dataset.drop(labels=range(3000), axis=1, inplace=True)\n",
    "    \n",
    "    for row in range(len(dataset)):\n",
    "        add_len(dataset.iloc[row])\n",
    "    dataset['length'] = len_list\n",
    "    \n",
    "    dataset['type'] = dataset_base.obs['celltype']\n",
    "    dataset['gene_name'] = range(dataset.shape[0])\n",
    "    \n",
    "    dataset.reset_index(inplace=True)\n",
    "    dataset.drop(labels=['index', 'gene_name'], axis=1, inplace=True)\n",
    "    dataset.rename_axis(None, axis=1, inplace=True)\n",
    "    \n",
    "    if is_oversample == False and is_undersample == False:\n",
    "        dataset['type'] = dataset['type'].apply(lambda x: convert_naming(x, type_to_index))\n",
    "    dataset.rename(columns={'type':'label'}, inplace=True)\n",
    "    \n",
    "    dataset = dataset[['label', 'input_ids', 'length']]\n",
    "    \n",
    "    if is_save:\n",
    "        dataset.to_csv(saving_name)\n",
    "        with open(f'dictionaries/index_to_type_{saving_name}.pkl', 'wb') as fp:\n",
    "            pickle.dump(index_to_type, fp)\n",
    "        with open(f'dictionaries/type_to_index_{saving_name}.pkl', 'wb') as fp:\n",
    "            pickle.dump(type_to_index, fp)\n",
    "    \n",
    "    return dataset, index_to_type, type_to_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a761be-be9e-46bf-b053-562be15a6687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_csv_dataset(path):\n",
    "    def convert_list_values_to_int(x):\n",
    "        lst = [int(i) for i in x]\n",
    "        return lst\n",
    "    \n",
    "    dataset = pd.read_csv(path)\n",
    "    \n",
    "    dataset.drop(labels='Unnamed: 0', axis=1, inplace=True)\n",
    "    dataset['label'] = dataset['label'].astype(int)\n",
    "    dataset['input_ids'] = dataset['input_ids'].str.strip('[]').str.split(', ')\n",
    "    dataset['input_ids'] = dataset['input_ids'].apply(convert_list_values_to_int)\n",
    "    dataset['length'] = dataset['length'].astype(int)\n",
    "    \n",
    "    return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "eba1599a1f7e611c14c87ccff6793920aa63510b01fc0e229d6dd014149b8829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
